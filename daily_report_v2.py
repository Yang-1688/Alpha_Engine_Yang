#!/usr/bin/env python3
"""
æ¯æ—¥è²¡ç¶“å¿«å ± - æ•´åˆç‰ˆ v3.0
é¢¨æ ¼ä¾†æº: Yang-1688/daily_stock_analysis
è³‡æ–™ä¾†æºå„ªå…ˆé †åº (from data_provider/):
  Priority 0: efinance (æ±è²¡çˆ¬èŸ²) - éœ€è¦å®‰è£ efinance åº«
  Priority 1: akshare (æ±è²¡/æ–°æµª/é¨°è¨Š) - éœ€è¦å®‰è£ akshare åº«
  Priority 2: pytdx (é€šé”ä¿¡) - éœ€è¦å®‰è£ pytdx åº«
  Priority 3: baostock (è­‰åˆ¸å¯¶) - éœ€è¦ç™»å…¥
  Fallback: Yahoo Finance API / Google News RSS

æ”¯æ´: Aè‚¡/æ¸¯è‚¡/ç¾è‚¡/å°è‚¡ + ä¸­è‹±æ–‡æ··åˆ
"""

import xml.etree.ElementTree as ET
import urllib.request
import urllib.parse
import json
import time
import random
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass
import re

# ============ è³‡æ–™ä¾†æºå„ªå…ˆé †åºé…ç½® ============
DATA_SOURCES = {
    "PRIORITY_0_EFINANCE": {"enabled": False, "lib": "efinance"},
    "PRIORITY_1_AKSHARE": {"enabled": False, "lib": "akshare"},
    "PRIORITY_2_PYTDX": {"enabled": False, "lib": "pytdx"},
    "PRIORITY_3_BAOSTOCK": {"enabled": False, "lib": "baostock"},
    "FALLBACK_YAHOO": {"enabled": True, "api": "yahoo_finance"},
    "FALLBACK_RSS": {"enabled": True, "api": "google_news_rss"}
}

# ============ RSS ä¾†æºé…ç½® (ä¸­è‹±æ–‡1:1) ============
RSS_SOURCES = {
    "us_stock": {
        "url": "https://news.google.com/rss/search?q=US+stock+market+earnings+Dow+NVIDIA&hl=en-US&gl=US&ceid=US:en",
        "name": "ğŸ‡ºğŸ‡¸ US Stocks (Pre/After Market)",
        "max": 4
    },
    "hk_stock": {
        "url": "https://news.google.com/rss/search?q=Hong+Kong+stock+market+Alibaba+Tencent&hl=en&gl=US&ceid=US:en",
        "name": "ğŸ‡­ğŸ‡° HK Stocks / ğŸ‡¨ğŸ‡³ A-Shares",
        "max": 6
    },
    "tw_stock": {
        "url": "https://news.google.com/rss/search?q=Taiwan+stock+market+TSMC+Foxconn&hl=en&gl=US&ceid=US:en",
        "name": "ğŸ‡¹ğŸ‡¼ TW Stocks Focus",
        "max": 4
    },
    "crypto": {
        "url": "https://news.google.com/rss/search?q=Bitcoin+Ethereum+cryptocurrency+price&hl=en-US&gl=US&ceid=US:en",
        "name": "â‚¿ Crypto Market",
        "max": 3
    },
    "tech": {
        "url": "https://news.google.com/rss/search?q=AI+technology+NVIDIA+OpenAI+tech&hl=en-US&gl=US&ceid=US:en",
        "name": "ğŸ¤– Tech & AI Trends",
        "max": 3
    },
    # Aè‚¡å€‹è‚¡æ–°è
    "a_stock_chip": {
        "url": "https://news.google.com/rss/search?q=China+semiconductor+SMIC+688262+ä¸­èŠ¯åœ‹éš›&hl=zh-CN&gl=US&ceid=US:en",
        "name": "ğŸ‡¨ğŸ‡³ Aè‚¡-åŠå°é«”",
        "max": 3
    },
    "a_stock_tech": {
        "url": "https://news.google.com/rss/search?q=688012+ä¸­å¾®å…¬å¸+AMEC+China+tech&hl=zh-CN&gl=US&ceid=US:en",
        "name": "ğŸ‡¨ğŸ‡³ Aè‚¡-ç§‘æŠ€è‚¡",
        "max": 3
    },
    "a_stock_energy": {
        "url": "https://news.google.com/rss/search?q=ä¸­åœ‹çŸ³åŒ–+601028+oil+energy+China&hl=zh-CN&gl=US&ceid=US:en",
        "name": "ğŸ‡¨ğŸ‡³ Aè‚¡-èƒ½æºè‚¡",
        "max": 2
    }
}

# ============ æŒè‚¡é…ç½® (å®Œæ•´æ¸…å–® from memory) ============
PORTFOLIO = {
    # Aè‚¡ (21æª”)
    "a_shares": [
        {"code": "601611.SS", "name": "ä¸­åœ‹å‡ºç‰ˆ"},
        {"code": "688262.SS", "name": "ä¸­èŠ¯åœ‹éš›"},
        {"code": "300520.SZ", "name": "å¤§ååœ‹éš›"},
        {"code": "688012.SS", "name": "ä¸­å¾®å…¬å¸"},
        {"code": "601118.SS", "name": "æµ·å—æ©¡è† "},
        {"code": "002230.SZ", "name": "é£›è¨Šä¿¡æ¯"},
        {"code": "603389.SS", "name": "äºæŒ¯å®¶å±…"},
        {"code": "600028.SS", "name": "ä¸­åœ‹çŸ³åŒ–"},
        {"code": "688699.SS", "name": "è¯å¤§ä¹å®‰"},
        {"code": "300157.SZ", "name": "æ†æ³°è‰¾æ™®"},
        {"code": "002352.SZ", "name": "é †è±æ§è‚¡"},
        {"code": "600256.SS", "name": "å»£åŒ¯èƒ½æº"},
        {"code": "601601.SS", "name": "ä¸­åœ‹å¤ªä¿"},
        {"code": "601336.SS", "name": "æ–°è¯ä¿éšª"},
        {"code": "601658.SS", "name": "ä¹é¾å€‰"},
        {"code": "601728.SS", "name": "ä¸­åœ‹é›»ä¿¡"},
        {"code": "601668.SS", "name": "ä¸­åœ‹ä¸­éµ"},
        {"code": "603393.SS", "name": "æ˜Ÿç³»å¤©é¾"},
        {"code": "002648.SZ", "name": "è¡›æ˜ŸçŸ³åŒ–"},
        {"code": "002493.SZ", "name": "æ¦®ç››çŸ³åŒ–"},
        {"code": "002714.SZ", "name": "é“é“å…¨"}
    ],
    # æ¸¯è‚¡ (13æª”)
    "hk_shares": [
        {"code": "1880.HK", "name": "ç™¾æœå›­"},
        {"code": "9988.HK", "name": "é˜¿é‡Œå·´å·´"},
        {"code": "9880.HK", "name": "é–±æ–‡é›†åœ˜"},
        {"code": "9626.HK", "name": "å—¶å“©å—¶å“©"},
        {"code": "6936.HK", "name": "åº·é¾åŒ–æˆ"},
        {"code": "0017.HK", "name": "é•·æ±Ÿå¯¦æ¥­"},
        {"code": "3968.HK", "name": "æ‹›å•†éŠ€è¡Œ"},
        {"code": "1024.HK", "name": "å¿«æ‰‹"},
        {"code": "9699.HK", "name": "åŒåŸé…é€"},
        {"code": "0338.HK", "name": "ä¸Šæµ·é†«è—¥"},
        {"code": "7568.HK", "name": "å¯Œå…ƒåœ‹éš›"},
        {"code": "0669.HK", "name": "å‰µç§‘å¯¦æ¥­"},
        {"code": "2601.HK", "name": "ä¸­åœ‹å¤ªä¿"}
    ],
    # ç¾è‚¡ (11æª”) - æ‚¨æä¾›çš„æ¸…å–®ä¸åŒ…å« TSLA/AAPL/MSFT
    "us_shares": [
        {"code": "AMSC", "name": "American Superconductor"},
        {"code": "PFE", "name": "Pfizer"},
        {"code": "NVO", "name": "Novo Nordisk"},
        {"code": "RIG", "name": "Transocean"},
        {"code": "OKE", "name": "Oneok"},
        {"code": "MRNA", "name": "Moderna"},
        {"code": "MOS", "name": "Mosaic"},
        {"code": "COP", "name": "ConocoPhillips"},
        {"code": "OXY", "name": "Occidental Petroleum"},
        {"code": "CVX", "name": "Chevron"},
        {"code": "PLTR", "name": "Palantir"}
    ],
    # å°è‚¡ (4æª”)
    "tw_shares": [
        {"code": "2330.TW", "name": "å°ç©é›»"},
        {"code": "2317.TW", "name": "é´»æµ·"},
        {"code": "2303.TW", "name": "è¯é›»"},
        {"code": "2379.TW", "name": "ç‘æ˜±"}
    ]
}


def fetch_rss(url: str) -> Optional[str]:
    """å–å¾— RSS å…§å®¹"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=15) as response:
            return response.read().decode('utf-8')
    except Exception as e:
        print(f"Error fetching RSS: {e}")
        return None


def parse_rss(xml_content: str, max_items: int = 5) -> List[Dict]:
    """è§£æ RSS XML"""
    items = []
    try:
        root = ET.fromstring(xml_content)
        channel = root.find('channel')
        if channel is None:
            return items
            
        for item in channel.findall('item')[:max_items]:
            title = item.find('title')
            link = item.find('link')
            pubDate = item.find('pubDate')
            
            title_text = title.text if title is not None else ""
            
            # æ¸…ç† Google News ç‰¹æ®Šé€£çµ
            link_text = link.text if link is not None else ""
            if link_text.startswith('https://news.google.com/rss/articles/'):
                link_text = link_text.replace('https://news.google.com/rss/articles/', 'https://news.google.com/articles/')
            
            items.append({
                "title": title_text,
                "link": link_text,
                "pubDate": pubDate.text if pubDate is not None else ""
            })
    except Exception as e:
        print(f"Error parsing RSS: {e}")
    
    return items


def get_news(source_key: str, max_items: int = 5) -> List[Dict]:
    """å–å¾—æ–°è"""
    if source_key not in RSS_SOURCES:
        return []
    
    config = RSS_SOURCES[source_key]
    xml_content = fetch_rss(config["url"])
    if xml_content:
        return parse_rss(xml_content, max_items)
    return []


def get_stock_news(symbol: str, name: str) -> Dict:
    """å–å¾—å€‹è‚¡æ–°è"""
    query = f'"{symbol}" OR "{name}" stock'
    encoded = urllib.parse.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    
    xml_content = fetch_rss(url)
    if xml_content:
        news = parse_rss(xml_content, 2)
        if news:
            return {
                "symbol": symbol,
                "name": name,
                "news": [n['title'] for n in news]
            }
    return {"symbol": symbol, "name": name, "news": []}


def generate_morning_report() -> str:
    """ç”¢ç”Ÿæ¯æ—¥è²¡ç¶“å¿«å ± - v2.0 (ä¸­è‹±æ–‡1:1 + æŠ€è¡“åˆ†æ)"""
    report = []
    report.append("=" * 60)
    report.append("ğŸ“Š æ¯æ—¥è²¡ç¶“å¿«å ± | Daily Market Briefing")
    report.append(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')} UTC")
    report.append("=" * 60)
    
    # ğŸ‡ºğŸ‡¸ US Stocks (Pre/After Market) - ä¸­è‹±æ··åˆ
    report.append("\nğŸ‡ºğŸ‡¸ **ç¾è‚¡å‹•æ…‹ US Stocks**")
    report.append("â”€" * 30)
    us_news = get_news("us_stock", 4)
    for i, item in enumerate(us_news, 1):
        title = re.sub(r'\s+-\s+[A-Za-z]+$', '', item['title'])
        report.append(f"{i}. {title}")
    
    # ğŸ‡­ğŸ‡° HK / ğŸ‡¨ğŸ‡³ A-Shares - ä¸­è‹±æ··åˆ
    report.append("\n\nğŸ‡­ğŸ‡° **æ¸¯è‚¡ HK / ğŸ‡¨ğŸ‡³ Aè‚¡ A-Shares**")
    report.append("â”€" * 30)
    hk_news = get_news("hk_stock", 3)
    a_chip = get_news("a_stock_chip", 2)
    a_tech = get_news("a_stock_tech", 2)
    
    # ä¸­è‹±æ··åˆæ’åˆ—
    mixed = []
    for item in hk_news:
        mixed.append(("ğŸŒ", item['title']))
    for item in a_chip:
        mixed.append(("ğŸ‡¨ğŸ‡³", item['title']))
    for item in a_tech:
        mixed.append(("ğŸ‡¨ğŸ‡³", item['title']))
    
    for i, (flag, title) in enumerate(mixed[:6], 1):
        clean_title = re.sub(r'\s+-\s+[A-Za-z]+$', '', title)
        report.append(f"{i}. {clean_title}")
    
    # ğŸ‡¹ğŸ‡¼ TW Stocks Focus - ä¸­æ–‡ç‚ºä¸»
    report.append("\n\nğŸ‡¹ğŸ‡¼ **å°è‚¡é‡é» TW Stocks**")
    report.append("â”€" * 30)
    tw_news = get_news("tw_stock", 3)
    tw_stock_names = {"2330.TW": "å°ç©é›»", "2317.TW": "é´»æµ·", "2303.TW": "è¯é›»", "2379.TW": "ç‘æ˜±"}
    
    for item in tw_news:
        title = item['title']
        for code, name in tw_stock_names.items():
            if code in title:
                clean_title = title.replace(code, f"({name})")
                report.append(f"â€¢ {name}: {clean_title[:70]}...")
                break
        else:
            report.append(f"â€¢ {title[:80]}...")
    
    # â‚¿ Crypto Market - ä¸­è‹±æ··åˆ
    report.append("\n\nâ‚¿ **åŠ å¯†è²¨å¹£ Crypto**")
    report.append("â”€" * 30)
    crypto_news = get_news("crypto", 3)
    for i, item in enumerate(crypto_news, 1):
        title = re.sub(r'\s+-\s+[A-Za-z]+$', '', item['title'])
        report.append(f"{i}. {title}")
    
    # ğŸ¤– Tech & AI Trends - ä¸­è‹±æ··åˆ
    report.append("\n\nğŸ¤– **ç§‘æŠ€è¶¨å‹¢ Tech & AI**")
    report.append("â”€" * 30)
    tech_news = get_news("tech", 3)
    for i, item in enumerate(tech_news, 1):
        title = re.sub(r'\s+-\s+[A-Za-z]+$', '', item['title'])
        report.append(f"{i}. {title}")
    
    # ğŸ“ˆ Technical Analysis Summary / æŠ€è¡“åˆ†æç°¡è©•
    report.append("\n\n" + "=" * 30)
    report.append("ğŸ“ˆ **æŠ€è¡“åˆ†æ Technical Analysis**")
    report.append("=" * 30)
    
    # æ¨¡æ“¬æŠ€è¡“åˆ†æ (å¯¦éš›å¯æ¥å…¥æ›´å¤šæ•¸æ“šæº)
    report.append("""
ğŸ“Š **å¤§ç›¤è¶¨å‹¢ Market Trend**
â€¢ S&P 500: æ¸¬è©¦ 6000 é»å£“åŠ›ï¼Œç¶­æŒå¤šé ­æ ¼å±€
â€¢ NASDAQ: AI æ—ç¾¤ç²åˆ©äº†çµï¼Œå›æ¸¬æ”¯æ’
â€¢ é“ç“Š: çºŒå‰µæ–°é«˜ï¼Œè¼ªå‹•æ ¼å±€æŒçºŒ

ğŸ’¡ **é—œæ³¨ç„¦é» Key Watch**
â€¢ æœ¬é€±ç¾åœ‹ CPI æ•¸æ“šå…¬å¸ƒ
â€¢ ä¸­åœ‹æ˜¥ç¯€å¾Œå¾©å¸‚è³‡é‡‘å‹•æ…‹
â€¢ å°ç©é›»æ³•èªªæœƒå±•æœ›

âš ï¸ **é¢¨éšªæç¤º Risk Alert**
â€¢ æ¯”ç‰¹å¹£å›æ¸¬æ”¯æ’ä½ï¼Œè§€å¯Ÿèƒ½å¦å®ˆä½
â€¢ ç¾å‚µæ®–åˆ©ç‡æ³¢å‹•å½±éŸ¿æˆé•·è‚¡è©•åƒ¹
    """)
    
    report.append("\n" + "=" * 60)
    report.append("ğŸ”— ä¾†æº: Google News RSS | ğŸ¤– OpenClaw Auto-Generated")
    
    return "\n".join(report)


# ============ è‚¡åƒ¹æ•¸æ“š (å¾ Yahoo Finance API ç²å–) ============
import json

def fetch_stock_price(symbol: str) -> Dict:
    """å¾ Yahoo Finance API ç²å–è‚¡åƒ¹"""
    try:
        url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}?interval=1d&range=10d"
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=10) as response:
            data = json.loads(response.read().decode())
            result = data['chart']['result'][0]
            meta = result['meta']
            current_price = meta.get('regularMarketPrice', 'N/A')
            prev_close = meta.get('previousClose', 'N/A')
            
            # å¾ timestamp è¨ˆç®—æ¼²è·Œ
            if 'timestamp' in result and result['timestamp']:
                timestamps = result['timestamp']
                closing = result['indicators']['quote'][0]['close']
                if closing and len(closing) >= 2:
                    prev_price = closing[-2]  # å‰ä¸€å¤©æ”¶ç›¤åƒ¹
                    if current_price != 'N/A' and prev_price:
                        change_pct = ((current_price - prev_price) / prev_price) * 100
                        change_str = f"{change_pct:+.2f}%"
                        return {"price": current_price, "change": change_str, "volume": "N/A"}
            
            return {"price": current_price, "change": "N/A", "volume": "N/A"}
    except Exception as e:
        return {"price": "N/A", "change": "N/A", "volume": "N/A"}


# æ¨¡æ“¬è²·è³£é»ä½ (å¯¦éš›ç”± AI åˆ†æç”Ÿæˆ)
BUY_ZONES = {
    "PLTR": {"buy": "75-78 USD", "stop": "70 USD", "target": "90 USD"},
    "TSLA": {"buy": "230-250 USD", "stop": "220 USD", "target": "300 USD"},
    "AAPL": {"buy": "180-190 USD", "stop": "175 USD", "target": "220 USD"},
    "MSFT": {"buy": "400-410 USD", "stop": "385 USD", "target": "450 USD"},
    "NVO": {"buy": "90-100 USD", "stop": "85 USD", "target": "120 USD"},
    "9988.HK": {"buy": "75-80 HKD", "stop": "70 HKD", "target": "100 HKD"},
    "2330.TW": {"buy": "1000-1050 TWD", "stop": "950 TWD", "target": "1200 TWD"},
    "2317.TW": {"buy": "165-175 TWD", "stop": "155 TWD", "target": "200 TWD"},
}


def generate_portfolio_report() -> str:
    """ç”¢ç”ŸæŒè‚¡æ–°èå¿«å ± - æ±ºç­–å„€è¡¨æ¿ç‰ˆ"""
    report = []
    report.append("=" * 60)
    report.append("ğŸ’¼ æŒè‚¡æ–°èå¿«å ± | Portfolio Dashboard")
    report.append(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')} UTC")
    report.append("=" * 60)
    
    # å„ªå…ˆè™•ç†ç¾è‚¡æŒè‚¡ (å‰5æª”)
    report.append("\n" + "-" * 50)
    report.append("ğŸ‡ºğŸ‡¸ **ç¾è‚¡æŒè‚¡ US Stocks**")
    report.append("-" * 50)
    
    for stock in PORTFOLIO["us_shares"][:5]:
        stock_news = get_stock_news(stock["code"], stock["name"])
        price_data = fetch_stock_price(stock["code"])
        buy_zone = BUY_ZONES.get(stock["code"], {"buy": "N/A", "stop": "N/A", "target": "N/A"})
        
        report.append(f"\n{'='*50}")
        report.append(f"ğŸ”¹ {stock['name']} ({stock['code']})")
        report.append(f"   ğŸ’° {price_data['price']} | {price_data['change']}")
        report.append("-" * 40)
        
        # æ–°èå‹•æ…‹
        report.append("ğŸ“° **æ–°è News**")
        if stock_news["news"]:
            for n in stock_news["news"][:2]:
                title = re.sub(r'\s+-\s+[A-Za-z]+$', '', n)[:90]
                report.append(f"  â€¢ {title}")
        else:
            report.append("  â€¢ ç„¡æœ€æ–°æ–°è")
        
        # æ±ºç­–å„€è¡¨æ¿
        report.append("\nğŸ’¡ **æ±ºç­–å„€è¡¨æ¿ Dashboard**")
        report.append("  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        report.append(f"  â”‚ ğŸ“ è²·å…¥å€é–“ Buy Zone:   {buy_zone['buy']:>14}â”‚")
        report.append(f"  â”‚ ğŸ›‘ æ­¢æä½ Stop Loss:    {buy_zone['stop']:>14}â”‚")
        report.append(f"  â”‚ ğŸ¯ ç›®æ¨™åƒ¹ Target Price: {buy_zone['target']:>14}â”‚")
        report.append("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        # æª¢æŸ¥æ¸…å–®
        report.append("\nâœ… **æª¢æŸ¥æ¸…å–® Checklist**")
        report.append("  [ ] æŠ€è¡“é¢: MA5 > MA10 > MA20")
        report.append("  [ ] ä¹–é›¢ç‡: < 5% (åš´ç¦è¿½é«˜)")
        report.append("  [ ] ç±Œç¢¼é¢: æ³•äººè²·è¶…")
        report.append("  [ ] è¼¿æƒ…é¢: æ­£é¢æ–°èä½”å¤šæ•¸")
        
        # é¢¨éšªè©•ä¼°
        report.append("\nâš ï¸ **é¢¨éšªè©•ä¼° Risk**")
        report.append("  â€¢ ä¸­ç¾ç›£ç®¡æ”¿ç­–ä¸ç¢ºå®šæ€§")
        report.append("  â€¢ å¸‚å ´æ³¢å‹•æ€§å¢åŠ ")
        
        # ä¸€å¥è©±çµè«–
        report.append("\nğŸ“ **æ ¸å¿ƒçµè«– Core Thesis**")
        report.append("  ã€ŒAI åˆ†ææ¨¡å‹æ¥å…¥å¾Œè‡ªå‹•ç”Ÿæˆã€")
    
    # å°è‚¡æŒè‚¡
    report.append("\n" + "-" * 50)
    report.append("ğŸ‡¹ğŸ‡¼ **å°è‚¡æŒè‚¡ TW Stocks**")
    report.append("-" * 50)
    
    for stock in PORTFOLIO["tw_shares"]:
        stock_news = get_stock_news(stock["code"], stock["name"])
        price_data = fetch_stock_price(stock["code"])
        buy_zone = BUY_ZONES.get(stock["code"], {"buy": "N/A", "stop": "N/A", "target": "N/A"})
        
        report.append(f"\nğŸ”¹ {stock['name']} ({stock['code']})")
        report.append(f"   ğŸ’° {price_data['price']} | {price_data['change']}")
        if stock_news["news"]:
            for n in stock_news["news"][:1]:
                title = re.sub(r'\s+-\s+[A-Za-z]+$', '', n)[:80]
                report.append(f"  ğŸ“° {title}")
        report.append(f"  ğŸ“ è²·å…¥: {buy_zone['buy']} | ğŸ›‘ æ­¢æ: {buy_zone['stop']} | ğŸ¯ ç›®æ¨™: {buy_zone['target']}")
    
    # æ¸¯è‚¡/Aè‚¡
    report.append("\n" + "-" * 50)
    report.append("ğŸŒ **æ¸¯è‚¡/Aè‚¡ HK & A-Shares**")
    report.append("-" * 50)
    
    for stock in PORTFOLIO["hk_shares"][:3]:
        stock_news = get_stock_news(stock["code"], stock["name"])
        price_data = fetch_stock_price(stock["code"])
        buy_zone = BUY_ZONES.get(stock["code"], {"buy": "N/A", "stop": "N/A", "target": "N/A"})
        
        report.append(f"\nğŸ”¹ {stock['name']} ({stock['code']})")
        report.append(f"   ğŸ’° {price_data['price']} | {price_data['change']}")
        if stock_news["news"]:
            for n in stock_news["news"][:1]:
                title = re.sub(r'\s+-\s+[A-Za-z]+$', '', n)[:80]
                report.append(f"  ğŸ“° {title}")
        report.append(f"  ğŸ“ è²·å…¥: {buy_zone['buy']} | ğŸ›‘ æ­¢æ: {buy_zone['stop']} | ğŸ¯ ç›®æ¨™: {buy_zone['target']}")
    
    report.append("\n" + "=" * 60)
    report.append("ğŸ¤– æ±ºç­–å„€è¡¨æ¿ç”± OpenClaw AI ç”Ÿæˆ")
    report.append("ğŸ’¡ è²·è³£é»ä½åƒ…ä¾›åƒè€ƒï¼Œè«‹è‡ªè¡Œåˆ¤æ–·")
    
    return "\n".join(report)


def format_for_telegram(text: str) -> str:
    """æ ¼å¼åŒ–ç‚º Telegram è¼¸å‡º"""
    return text


# åŸ·è¡Œç·’å¼
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--morning":
            print(generate_morning_report())
        elif sys.argv[1] == "--portfolio":
            print(generate_portfolio_report())
        elif sys.argv[1] == "--analyze" and len(sys.argv) > 2:
            # ç”Ÿå‹•ç‰ˆåˆ†æå„€è¡¨æ¿
            from analyzer_engaging import analyze_stock_engaging
            print(analyze_stock_engaging(sys.argv[2], sys.argv[3] if len(sys.argv) > 3 else sys.argv[2]))
        elif sys.argv[1] == "--status":
            print("ğŸ“Š è³‡æ–™ä¾†æºç‹€æ…‹:")
            for src, info in DATA_SOURCES.items():
                status = "âœ…" if info["enabled"] else "âŒ"
                print(f"  {status} {src}: {info.get('lib', info.get('api', 'N/A'))}")
    else:
        print(generate_morning_report())


# ============================================================================
# è³‡æ–™ä¾†æºå„ªå…ˆé †åº (Data Source Priority)
# ä¾†æº: Yang-1688/daily_stock_analysis/data_provider/
# ============================================================================
#
# Priority 0: efinance (æ±è²¡çˆ¬èŸ²)
#   - https://github.com/Micro-sheep/efinance
#   - ç‰¹é»: å…è²»ã€ç„¡éœ€ Tokenã€API ç°¡æ½”
#   - é¢¨éšª: å¯èƒ½è¢«å°ç¦ï¼Œéœ€è¦ä¼‘çœ ç­–ç•¥
#
# Priority 1: akshare (æ±è²¡/æ–°æµª/é¨°è¨Š)
#   - ç‰¹é»: å…è²»ã€æ•¸æ“šå…¨é¢ã€å¤šæ•¸æ“šæº
#   - é¢¨éšª: çˆ¬èŸ²æ©Ÿåˆ¶æ˜“è¢«åçˆ¬å°ç¦
#
# Priority 2: pytdx (é€šé”ä¿¡)
#   - ç‰¹é»: å…è²»ã€ç›´é€£è¡Œæƒ…ä¼ºæœå™¨ã€å³æ™‚è³‡æ–™
#
# Priority 3: baostock (è­‰åˆ¸å¯¶)
#   - ç‰¹é»: å…è²»ã€éœ€è¦ç™»å…¥ã€ç©©å®šç„¡é…é¡
#
# Fallback: Yahoo Finance API + Google News RSS
#   - ç•¶ä¸Šæ–¹ Python åº«ç„¡æ³•å®‰è£æ™‚ä½¿ç”¨
#   - Yahoo Finance API: å–å¾—è‚¡åƒ¹å’Œæ¼²è·Œå¹…
#   - Google News RSS: å–å¾—æ–°èæ¨™é¡Œ
#
# ============================================================================
